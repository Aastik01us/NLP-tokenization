{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpI69SwEwO5GxsXimIESIc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aastik01us/NLP-tokenization/blob/main/data_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y serpapi\n",
        "!pip install serpapi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKTNwMNZ6Ffd",
        "outputId": "333cf43b-ce85-471b-ab03-9b031f5e061d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: serpapi 0.1.5\n",
            "Uninstalling serpapi-0.1.5:\n",
            "  Successfully uninstalled serpapi-0.1.5\n",
            "Collecting serpapi\n",
            "  Using cached serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from serpapi) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->serpapi) (2025.7.14)\n",
            "Using cached serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: serpapi\n",
            "Successfully installed serpapi-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "companies = [\n",
        "    \"TCS\", \"Accenture\", \"Cognizant\", \"ICICI Bank\", \"HDFC Bank\", \"Wipro\", \"Infosys\", \"Capgemini\", \"Tech Mahindra\",\n",
        "    \"Genpact\", \"HCL Technologies\", \"Axis Bank\", \"Amazon\", \"IBM\", \"Concentrix Corporation\", \"Larsen & Toubro\",\n",
        "    \"Reliance jio\", \"Vodafone Idea\", \"HDB Financial Services\", \"Teleperformance\", \"Kotak Mahindra Bank\",\n",
        "    \"Reliance Industries\", \"Bharti Airtel\", \"Deloitte\", \"Tata Motors\", \"Reliance Retail\", \"WNS\",\n",
        "    \"Mahindra & Mahindra\", \"IndusInd Bank\", \"Flipkart\", \"DXC Technology\", \"BYJU'S\", \"Hinduja Global Solutions\",\n",
        "    \"Ernst & Young\", \"Maruti Suzuki\", \"Infosys BPM\", \"HSBC\", \"Ericsson\", \"Bajaj Finserv\", \"IDFC FIRST Bank\",\n",
        "    \"Conneqt Business Solutions\", \"Dr. Reddy's\", \"Startek\", \"Mphasis\", \"Sutherland Global Services\",\n",
        "    \"Cipla Pharmaceuticals\", \"Jana Small Finance Bank\", \"Yes Bank\", \"Asian Paints\",\n",
        "    \"ICICI Prudential Life Insurance\", \"HCL Group\", \"NTT DATA\", \"Udaan\", \"HDFC Life\", \"Indian Army\",\n",
        "    \"EXL Service\", \"Home Credit Finance\", \"L&T Infotech\", \"PwC\", \"Lupin\", \"UltraTech Cement\", \"Bajaj Finance\",\n",
        "    \"Hindustan Unilever\", \"ITC\", \"Ujjivan Small Finance Bank\", \"Zydus Cadila\", \"Paytm\", \"OPPO\", \"KPMG\",\n",
        "    \"Mindtree\", \"IIFL\", \"Shapoorji Pallonji Group\", \"JP Morgan Chase\", \"Shriram Transport Finance\",\n",
        "    \"Ashok Leyland\", \"Sun Pharmaceuticals\", \"Vivo\", \"Aurobindo Pharma\", \"Wells Fargo India\",\n",
        "    \"Intelenet Global Services\", \"Fidelity National\", \"Apollo Hospitals\", \"Hewlett-Packard Enterprise\",\n",
        "    \"Bandhan Bank\", \"Reliance Communications\", \"iEnergizer\", \"Siemens\", \"Future Group\", \"Delhivery\", \"Nokia\",\n",
        "    \"eClerx\", \"Max Life Insurance\", \"AU Small Finance Bank\", \"First Source\", \"Oracle\", \"TVS Motor\",\n",
        "    \"Hero MotoCorp\", \"Oyo Rooms\", \"Tata Projects\", \"Wipro BPS\", \"Hexaware Technologies\", \"TATA Steel\",\n",
        "    \"JSW Steel\", \"JLL\", \"Cyient\", \"Hyundai Motor\"\n",
        "]\n",
        "df = pd.DataFrame({\"Company\": companies})\n",
        "df.to_csv(\"companies.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "Nats8M_k6ahv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googlesearch-python beautifulsoup4 pandas\n",
        "\n",
        "from googlesearch import search\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# 🗂️ Load your company list\n",
        "df = pd.read_csv(\"companies.csv\")\n",
        "companies = df[\"Company\"].tolist()\n",
        "\n",
        "# 📦 Store results here\n",
        "results = []\n",
        "\n",
        "# 🔎 Helper functions\n",
        "def find_links(company):\n",
        "    query_linkedin = f\"{company} site:linkedin.com/company\"\n",
        "    query_website = f\"{company} official site\"\n",
        "\n",
        "    linkedin_url = \"Not Found\"\n",
        "    website_url = \"Not Found\"\n",
        "\n",
        "    try:\n",
        "        for result in search(query_linkedin, num_results=3):\n",
        "            if \"linkedin.com/company\" in result:\n",
        "                linkedin_url = result\n",
        "                break\n",
        "        for result in search(query_website, num_results=3):\n",
        "            if \"http\" in result:\n",
        "                website_url = result\n",
        "                break\n",
        "    except:\n",
        "        pass\n",
        "    return linkedin_url, website_url\n",
        "\n",
        "def extract_email(website_url):\n",
        "    try:\n",
        "        response = requests.get(website_url, timeout=10)\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        text = soup.get_text()\n",
        "        emails = [word for word in text.split() if \"@\" in word and \".\" in word and \"@\" not in word[0]]\n",
        "        return emails[0] if emails else \"Not Found\"\n",
        "    except:\n",
        "        return \"Not Found\"\n",
        "\n",
        "# 🔁 Loop through companies\n",
        "for company in companies:\n",
        "    print(f\"🔍 {company}\")\n",
        "    linkedin, website = find_links(company)\n",
        "    email = extract_email(website)\n",
        "    results.append({\n",
        "        \"Company\": company,\n",
        "        \"LinkedIn URL\": linkedin,\n",
        "        \"Website\": website,\n",
        "        \"Email\": email\n",
        "    })\n",
        "\n",
        "# 💾 Save results\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_csv(\"company_data_output.csv\", index=False)\n",
        "print(\"✅ Done. Saved as company_data_output.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICSmQIsT6j9Y",
        "outputId": "525dad80-f7e1-4c60-8145-2058b9fcc0c9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googlesearch-python\n",
            "  Downloading googlesearch_python-1.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from googlesearch-python) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch-python) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch-python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch-python) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch-python) (2025.7.14)\n",
            "Downloading googlesearch_python-1.3.0-py3-none-any.whl (5.6 kB)\n",
            "Installing collected packages: googlesearch-python\n",
            "Successfully installed googlesearch-python-1.3.0\n",
            "🔍 TCS\n",
            "🔍 Accenture\n",
            "🔍 Cognizant\n",
            "🔍 ICICI Bank\n",
            "🔍 HDFC Bank\n",
            "🔍 Wipro\n",
            "🔍 Infosys\n",
            "🔍 Capgemini\n",
            "🔍 Tech Mahindra\n",
            "🔍 Genpact\n",
            "🔍 HCL Technologies\n",
            "🔍 Axis Bank\n",
            "🔍 Amazon\n",
            "🔍 IBM\n",
            "🔍 Concentrix Corporation\n",
            "🔍 Larsen & Toubro\n",
            "🔍 Reliance jio\n",
            "🔍 Vodafone Idea\n",
            "🔍 HDB Financial Services\n",
            "🔍 Teleperformance\n",
            "🔍 Kotak Mahindra Bank\n",
            "🔍 Reliance Industries\n",
            "🔍 Bharti Airtel\n",
            "🔍 Deloitte\n",
            "🔍 Tata Motors\n",
            "🔍 Reliance Retail\n",
            "🔍 WNS\n",
            "🔍 Mahindra & Mahindra\n",
            "🔍 IndusInd Bank\n",
            "🔍 Flipkart\n",
            "🔍 DXC Technology\n",
            "🔍 BYJU'S\n",
            "🔍 Hinduja Global Solutions\n",
            "🔍 Ernst & Young\n",
            "🔍 Maruti Suzuki\n",
            "🔍 Infosys BPM\n",
            "🔍 HSBC\n",
            "🔍 Ericsson\n",
            "🔍 Bajaj Finserv\n",
            "🔍 IDFC FIRST Bank\n",
            "🔍 Conneqt Business Solutions\n",
            "🔍 Dr. Reddy's\n",
            "🔍 Startek\n",
            "🔍 Mphasis\n",
            "🔍 Sutherland Global Services\n",
            "🔍 Cipla Pharmaceuticals\n",
            "🔍 Jana Small Finance Bank\n",
            "🔍 Yes Bank\n",
            "🔍 Asian Paints\n",
            "🔍 ICICI Prudential Life Insurance\n",
            "🔍 HCL Group\n",
            "🔍 NTT DATA\n",
            "🔍 Udaan\n",
            "🔍 HDFC Life\n",
            "🔍 Indian Army\n",
            "🔍 EXL Service\n",
            "🔍 Home Credit Finance\n",
            "🔍 L&T Infotech\n",
            "🔍 PwC\n",
            "🔍 Lupin\n",
            "🔍 UltraTech Cement\n",
            "🔍 Bajaj Finance\n",
            "🔍 Hindustan Unilever\n",
            "🔍 ITC\n",
            "🔍 Ujjivan Small Finance Bank\n",
            "🔍 Zydus Cadila\n",
            "🔍 Paytm\n",
            "🔍 OPPO\n",
            "🔍 KPMG\n",
            "🔍 Mindtree\n",
            "🔍 IIFL\n",
            "🔍 Shapoorji Pallonji Group\n",
            "🔍 JP Morgan Chase\n",
            "🔍 Shriram Transport Finance\n",
            "🔍 Ashok Leyland\n",
            "🔍 Sun Pharmaceuticals\n",
            "🔍 Vivo\n",
            "🔍 Aurobindo Pharma\n",
            "🔍 Wells Fargo India\n",
            "🔍 Intelenet Global Services\n",
            "🔍 Fidelity National\n",
            "🔍 Apollo Hospitals\n",
            "🔍 Hewlett-Packard Enterprise\n",
            "🔍 Bandhan Bank\n",
            "🔍 Reliance Communications\n",
            "🔍 iEnergizer\n",
            "🔍 Siemens\n",
            "🔍 Future Group\n",
            "🔍 Delhivery\n",
            "🔍 Nokia\n",
            "🔍 eClerx\n",
            "🔍 Max Life Insurance\n",
            "🔍 AU Small Finance Bank\n",
            "🔍 First Source\n",
            "🔍 Oracle\n",
            "🔍 TVS Motor\n",
            "🔍 Hero MotoCorp\n",
            "🔍 Oyo Rooms\n",
            "🔍 Tata Projects\n",
            "🔍 Wipro BPS\n",
            "🔍 Hexaware Technologies\n",
            "🔍 TATA Steel\n",
            "🔍 JSW Steel\n",
            "🔍 JLL\n",
            "🔍 Cyient\n",
            "🔍 Hyundai Motor\n",
            "✅ Done. Saved as company_data_output.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PhHa9TVu7C8B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}